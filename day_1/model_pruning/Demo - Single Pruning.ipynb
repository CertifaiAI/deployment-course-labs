{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "valued-minnesota",
   "metadata": {},
   "source": [
    "![logo](../../picture/license_header_logo.png)\n",
    "**Copyright (c) 2020-2021 CertifAI Sdn. Bhd.**\n",
    "\n",
    "This program is part of OSRFramework. You can redistribute it and/or modify\n",
    "it under the terms of the GNU Affero General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n",
    "GNU Affero General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU Affero General Public License\n",
    "along with this program. If not, see http://www.gnu.org/licenses/.\n",
    "\n",
    "Authored by: [Jacklyn Lim](mailto:jacklyn.lim@certifai.ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-beach",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "decent-agriculture",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "from utils import download_model, download_dataset, load_model_state_dict, load_dataset, load_image, inspect_module, compare_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-ensemble",
   "metadata": {},
   "source": [
    "## Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "electoral-closure",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # Note that the input of this layers is depending on your input image sizes\n",
    "        self.fc1 = nn.Linear(18496, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-narrative",
   "metadata": {},
   "source": [
    "## Download Model and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "measured-expense",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model already exists, skipping download\n",
      "data already exists, skipping download\n"
     ]
    }
   ],
   "source": [
    "# model download\n",
    "MODEL_DOWNLOAD_PATH = 'https://s3.eu-central-1.wasabisys.com/certifai/deployment-training-labs/models/fruit_classifier_state_dict.pt'\n",
    "MODEL_STATE_DICT_PATH = '../../resources/model/'\n",
    "MODEL_FILENAME = 'fruits_image_classification.zip'\n",
    "download_model(MODEL_DOWNLOAD_PATH, MODEL_STATE_DICT_PATH, MODEL_FILENAME)\n",
    "\n",
    "# data download\n",
    "DATA_DOWNLOAD_PATH = \"https://s3.eu-central-1.wasabisys.com/certifai/deployment-training-labs/fruits_image_classification-20210604T123547Z-001.zip\"\n",
    "DATA_SAVE_PATH = \"../../resources/data/\"\n",
    "DATA_ZIP_FILENAME = \"fruits_image_classification.zip\"\n",
    "download_dataset(DATA_DOWNLOAD_PATH, DATA_SAVE_PATH, DATA_ZIP_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c961e37e",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbabd705",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model = load_model_state_dict(model, MODEL_STATE_DICT_PATH + MODEL_FILENAME)\n",
    "\n",
    "original_model = copy.deepcopy(model)\n",
    "single_pruned_model = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-snake",
   "metadata": {},
   "source": [
    "## Local Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-toner",
   "metadata": {},
   "source": [
    "### Prune Model\n",
    "Pruning acts by removing weight from the parameters and replacing it with a new parameter called ``weight_orig``. ``weight_orig`` stores the unpruned version of \n",
    "the tensor. The ``bias`` was not pruned, so it will remain intact.\n",
    "\n",
    "The pruning mask generated by the pruning technique selected above is saved \n",
    "as a module buffer named ``weight_mask`` (i.e. appending ``\"_mask\"`` to the \n",
    "initial parameter ``name``). Hence you can see that initially Module Buffer List is empty but after pruning it contains ``weight_mask``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fossil-highway",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_prune(model, module):\n",
    "    prune.l1_unstructured(module, name=\"weight\", amount=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "geographic-repair",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mModule Before Pruning \u001b[0m\n",
      "\n",
      "Module Parameters:\n",
      "[('weight', Parameter containing:\n",
      "tensor([[[[ 7.8413e-02, -6.1813e-02, -8.1539e-03,  1.9616e-02,  3.5149e-02],\n",
      "          [-1.0102e-01,  1.1059e-02,  6.4063e-02,  6.7392e-02,  5.8826e-02],\n",
      "          [ 2.3068e-02, -1.0635e-01,  7.8187e-02, -8.9222e-02, -6.6019e-02],\n",
      "          [ 4.4278e-03,  3.7632e-02,  6.8275e-02, -1.5092e-02, -5.8075e-02],\n",
      "          [-7.7381e-03,  3.9115e-02, -6.3891e-02, -9.9119e-02,  5.6131e-02]],\n",
      "\n",
      "         [[-5.3576e-02, -4.2260e-02,  1.1709e-01, -5.5879e-02, -7.3201e-02],\n",
      "          [ 1.1009e-01, -3.2467e-02,  2.8705e-02,  1.3480e-01, -2.5989e-02],\n",
      "          [ 1.2869e-01,  1.1275e-01,  1.0845e-01,  5.3049e-02, -3.2747e-02],\n",
      "          [ 9.2628e-02, -5.9429e-02, -4.8797e-02, -3.7474e-02,  6.8518e-02],\n",
      "          [ 3.5430e-02,  9.2111e-02,  9.4129e-02,  2.4983e-02,  8.5755e-02]],\n",
      "\n",
      "         [[-1.0724e-01, -1.3468e-01, -1.1950e-01,  3.8523e-02,  8.1936e-02],\n",
      "          [-5.4905e-02,  4.0974e-02, -1.0695e-01, -2.7370e-02, -2.5292e-02],\n",
      "          [-5.6430e-02, -7.9165e-02,  2.9678e-02, -3.5022e-02, -4.7790e-02],\n",
      "          [ 5.6684e-02, -1.1153e-01,  5.1191e-02,  7.8209e-02, -9.5925e-02],\n",
      "          [-1.3347e-01, -8.4023e-03, -1.1207e-01,  2.4432e-02, -1.1667e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.1700e-02,  2.9676e-02, -3.1128e-02, -1.0366e-01,  4.3732e-02],\n",
      "          [ 3.9392e-02,  1.4168e-02,  7.4021e-02, -4.7708e-02,  1.0424e-01],\n",
      "          [-8.9294e-02,  1.0285e-01,  8.4486e-02, -1.0398e-01, -1.1351e-02],\n",
      "          [-6.3500e-02,  1.1228e-01, -6.1671e-03,  6.6752e-02,  9.8750e-02],\n",
      "          [-9.0442e-02,  6.8810e-02, -1.0180e-01, -3.2472e-02, -4.7764e-02]],\n",
      "\n",
      "         [[-1.0797e-01, -1.0875e-01, -1.1131e-01, -8.9271e-02, -6.4491e-02],\n",
      "          [-3.7913e-02,  6.4726e-02, -1.8501e-02, -1.1425e-01, -8.3750e-02],\n",
      "          [ 8.3092e-02, -1.1248e-01, -5.6682e-02, -1.0438e-01,  6.2318e-02],\n",
      "          [ 7.9042e-02,  1.0216e-02, -5.7988e-02, -2.7897e-02,  6.9322e-03],\n",
      "          [ 4.8448e-02,  2.0391e-03, -5.3808e-02,  5.6547e-03,  3.6381e-03]],\n",
      "\n",
      "         [[ 1.0300e-03,  5.0179e-02, -4.3565e-02,  7.2572e-03,  5.4124e-04],\n",
      "          [ 4.8820e-02, -7.0653e-02, -9.0281e-02, -9.3963e-02,  4.8682e-02],\n",
      "          [ 9.2024e-02,  1.1466e-01,  4.1304e-02, -2.3476e-02,  2.1537e-02],\n",
      "          [-1.1409e-01,  1.3415e-02, -3.8058e-02, -8.6186e-03,  6.6672e-02],\n",
      "          [-3.9680e-02, -8.7426e-02,  7.0188e-03, -3.2031e-02, -5.3588e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.8473e-02,  5.0196e-02,  2.0160e-01,  9.7984e-02,  2.5009e-02],\n",
      "          [ 1.9605e-01,  1.4638e-01,  1.8007e-01,  1.8443e-01,  2.0294e-01],\n",
      "          [ 1.0415e-01,  1.3990e-01,  6.0541e-02,  2.1526e-01,  1.3725e-01],\n",
      "          [ 1.1589e-01,  1.6257e-01,  2.4218e-01,  1.6251e-01,  1.6299e-01],\n",
      "          [ 2.2432e-01,  1.2916e-01,  1.2925e-01,  1.4558e-01,  6.1556e-03]],\n",
      "\n",
      "         [[-4.3148e-02, -8.3872e-02, -1.0463e-01, -1.0313e-01, -1.0679e-02],\n",
      "          [-4.4514e-02, -1.7781e-01,  1.8439e-02, -3.6602e-02, -5.5025e-02],\n",
      "          [-2.1365e-02, -5.6574e-02, -1.4126e-01, -2.1229e-02, -1.9024e-01],\n",
      "          [-1.4102e-01, -7.3285e-02, -1.6985e-01,  1.2509e-02,  1.4991e-02],\n",
      "          [-3.3179e-02, -1.4919e-02, -1.9353e-01,  7.1042e-03, -7.5098e-02]],\n",
      "\n",
      "         [[-1.4850e-01, -1.5650e-01, -6.2293e-02, -3.1254e-02, -1.3700e-01],\n",
      "          [-9.6176e-02, -8.7817e-02, -1.8758e-01, -1.3813e-02, -1.1378e-01],\n",
      "          [-1.6675e-01, -1.4626e-01, -3.2701e-02, -1.9738e-01, -1.3707e-02],\n",
      "          [-1.6095e-01, -7.0138e-02, -3.8303e-02, -1.3984e-01, -1.6842e-01],\n",
      "          [-9.8659e-02, -6.0224e-02, -9.8516e-02, -3.6652e-02, -3.1845e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5868e-02,  1.1156e-01, -7.6428e-02, -1.1454e-01,  2.0634e-04],\n",
      "          [ 3.2535e-02,  1.2758e-01,  1.2133e-01,  4.3590e-02,  4.8725e-02],\n",
      "          [ 6.6313e-02,  4.7934e-03, -1.0131e-01, -4.9207e-02, -1.1222e-01],\n",
      "          [ 9.4242e-02, -5.1883e-02, -8.6807e-02, -1.9119e-02,  6.4271e-02],\n",
      "          [ 5.8985e-02,  5.0556e-02, -6.0076e-03, -1.1460e-01, -8.4892e-02]],\n",
      "\n",
      "         [[-1.0210e-01, -3.3356e-02,  6.8442e-02, -1.0533e-01, -6.6530e-02],\n",
      "          [ 1.2210e-01,  9.3549e-02,  4.8391e-02,  6.2525e-02, -5.0338e-02],\n",
      "          [-5.0929e-02,  6.9581e-02,  3.5210e-02, -4.3730e-02,  6.8127e-02],\n",
      "          [-7.3258e-02,  5.3672e-03,  9.4400e-02,  2.8378e-02, -1.1191e-01],\n",
      "          [ 2.2790e-02, -1.2288e-02,  4.3978e-02,  4.9709e-02, -1.0626e-01]],\n",
      "\n",
      "         [[-1.4800e-03,  1.3957e-01, -5.3870e-02, -1.4735e-02, -3.6558e-02],\n",
      "          [ 2.2872e-02,  4.1648e-02,  1.1687e-01,  1.0451e-01, -2.7750e-02],\n",
      "          [ 6.8420e-02, -5.2341e-02,  4.7658e-03,  2.5515e-02,  1.6970e-02],\n",
      "          [ 7.5878e-02,  5.9692e-02,  1.1513e-02,  1.1892e-01, -1.6453e-02],\n",
      "          [ 1.4242e-01,  1.1877e-01,  3.8476e-02, -1.4359e-02,  8.9257e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2509e-03, -6.2850e-02,  6.2449e-02,  8.8063e-03,  1.1066e-01],\n",
      "          [-1.1357e-01,  2.8129e-02, -1.0557e-01, -5.1484e-02, -1.1428e-02],\n",
      "          [ 9.3807e-02, -4.8045e-02, -6.7114e-02, -7.5985e-03, -1.4176e-02],\n",
      "          [-9.1584e-02,  3.1793e-03,  6.1209e-02, -4.9748e-02, -9.1772e-02],\n",
      "          [-8.1790e-02,  5.4728e-02, -7.1925e-03,  8.3563e-02, -1.0623e-02]],\n",
      "\n",
      "         [[ 2.2407e-03,  9.5927e-02,  3.7693e-02, -8.1818e-02,  2.1211e-02],\n",
      "          [-3.3027e-03, -7.5978e-02,  9.9323e-02,  5.2697e-02, -4.8777e-02],\n",
      "          [-1.0300e-01,  4.8841e-02, -9.9435e-02,  2.3274e-02, -7.2229e-02],\n",
      "          [ 1.9267e-02,  2.2934e-02,  5.6305e-02, -3.4559e-02, -1.5818e-03],\n",
      "          [-6.1964e-02,  9.2878e-03,  6.8133e-03,  1.0045e-01,  1.1116e-01]],\n",
      "\n",
      "         [[-2.0545e-02, -4.8986e-02, -1.5022e-02, -7.6355e-02, -5.3015e-02],\n",
      "          [-7.5279e-02, -7.4780e-02,  9.0214e-02,  3.1220e-02, -4.7829e-02],\n",
      "          [-1.1381e-01,  5.0366e-02, -7.1502e-02, -1.1429e-01, -1.1277e-01],\n",
      "          [ 3.6967e-02,  2.3879e-02,  1.3410e-03, -1.1083e-01,  3.7554e-02],\n",
      "          [-9.8396e-02,  1.5629e-02,  1.3082e-02, -7.9784e-02, -3.2695e-03]]],\n",
      "\n",
      "\n",
      "        [[[-8.9665e-02,  9.2446e-02, -5.5544e-02,  4.0383e-02, -1.0420e-01],\n",
      "          [ 2.4109e-02, -1.2419e-01, -2.5740e-02,  1.4531e-02, -1.2879e-02],\n",
      "          [ 4.4249e-02,  7.0219e-02, -9.3717e-02,  6.7805e-02, -8.6757e-02],\n",
      "          [-8.8680e-02, -4.0521e-02,  8.7181e-02,  6.2588e-02, -2.4862e-02],\n",
      "          [-6.9430e-02, -6.0137e-02, -6.6538e-02,  4.2187e-02, -1.7755e-02]],\n",
      "\n",
      "         [[ 8.1395e-02,  9.8363e-03,  1.0527e-01,  1.6607e-01,  1.7367e-01],\n",
      "          [ 1.0350e-01,  1.9681e-01,  6.4469e-02,  1.8143e-01,  1.6519e-01],\n",
      "          [ 1.8380e-01,  1.4370e-01, -8.4148e-03,  1.4814e-01,  1.8127e-02],\n",
      "          [ 1.5250e-02,  7.8225e-03,  3.6438e-02, -1.5574e-02,  1.9019e-01],\n",
      "          [ 5.3622e-02,  1.6768e-01,  1.9022e-01,  1.5953e-01,  1.7719e-01]],\n",
      "\n",
      "         [[-4.5931e-02, -1.6706e-01,  1.1519e-02, -1.5817e-01, -2.3946e-02],\n",
      "          [-1.0723e-01,  1.2497e-02,  1.7487e-02, -6.8855e-02, -9.4047e-02],\n",
      "          [ 2.4828e-02, -1.0119e-01, -1.4636e-01, -1.3712e-01, -1.6228e-01],\n",
      "          [ 3.4236e-02,  2.9726e-02, -8.9387e-02, -1.1427e-02,  8.5002e-03],\n",
      "          [-8.8311e-02, -3.2206e-02, -7.8615e-02, -1.1632e-01, -1.2801e-01]]]],\n",
      "       requires_grad=True)), ('bias', Parameter containing:\n",
      "tensor([-0.0594, -0.0101, -0.5172, -0.0776, -0.1052, -0.1574],\n",
      "       requires_grad=True))]\n",
      "\n",
      "Module Buffer List:\n",
      "[]\n",
      "\n",
      "\u001b[1mModule After Pruning \u001b[0m\n",
      "\n",
      "Module Parameters:\n",
      "[('bias', Parameter containing:\n",
      "tensor([-0.0594, -0.0101, -0.5172, -0.0776, -0.1052, -0.1574],\n",
      "       requires_grad=True)), ('weight_orig', Parameter containing:\n",
      "tensor([[[[ 7.8413e-02, -6.1813e-02, -8.1539e-03,  1.9616e-02,  3.5149e-02],\n",
      "          [-1.0102e-01,  1.1059e-02,  6.4063e-02,  6.7392e-02,  5.8826e-02],\n",
      "          [ 2.3068e-02, -1.0635e-01,  7.8187e-02, -8.9222e-02, -6.6019e-02],\n",
      "          [ 4.4278e-03,  3.7632e-02,  6.8275e-02, -1.5092e-02, -5.8075e-02],\n",
      "          [-7.7381e-03,  3.9115e-02, -6.3891e-02, -9.9119e-02,  5.6131e-02]],\n",
      "\n",
      "         [[-5.3576e-02, -4.2260e-02,  1.1709e-01, -5.5879e-02, -7.3201e-02],\n",
      "          [ 1.1009e-01, -3.2467e-02,  2.8705e-02,  1.3480e-01, -2.5989e-02],\n",
      "          [ 1.2869e-01,  1.1275e-01,  1.0845e-01,  5.3049e-02, -3.2747e-02],\n",
      "          [ 9.2628e-02, -5.9429e-02, -4.8797e-02, -3.7474e-02,  6.8518e-02],\n",
      "          [ 3.5430e-02,  9.2111e-02,  9.4129e-02,  2.4983e-02,  8.5755e-02]],\n",
      "\n",
      "         [[-1.0724e-01, -1.3468e-01, -1.1950e-01,  3.8523e-02,  8.1936e-02],\n",
      "          [-5.4905e-02,  4.0974e-02, -1.0695e-01, -2.7370e-02, -2.5292e-02],\n",
      "          [-5.6430e-02, -7.9165e-02,  2.9678e-02, -3.5022e-02, -4.7790e-02],\n",
      "          [ 5.6684e-02, -1.1153e-01,  5.1191e-02,  7.8209e-02, -9.5925e-02],\n",
      "          [-1.3347e-01, -8.4023e-03, -1.1207e-01,  2.4432e-02, -1.1667e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.1700e-02,  2.9676e-02, -3.1128e-02, -1.0366e-01,  4.3732e-02],\n",
      "          [ 3.9392e-02,  1.4168e-02,  7.4021e-02, -4.7708e-02,  1.0424e-01],\n",
      "          [-8.9294e-02,  1.0285e-01,  8.4486e-02, -1.0398e-01, -1.1351e-02],\n",
      "          [-6.3500e-02,  1.1228e-01, -6.1671e-03,  6.6752e-02,  9.8750e-02],\n",
      "          [-9.0442e-02,  6.8810e-02, -1.0180e-01, -3.2472e-02, -4.7764e-02]],\n",
      "\n",
      "         [[-1.0797e-01, -1.0875e-01, -1.1131e-01, -8.9271e-02, -6.4491e-02],\n",
      "          [-3.7913e-02,  6.4726e-02, -1.8501e-02, -1.1425e-01, -8.3750e-02],\n",
      "          [ 8.3092e-02, -1.1248e-01, -5.6682e-02, -1.0438e-01,  6.2318e-02],\n",
      "          [ 7.9042e-02,  1.0216e-02, -5.7988e-02, -2.7897e-02,  6.9322e-03],\n",
      "          [ 4.8448e-02,  2.0391e-03, -5.3808e-02,  5.6547e-03,  3.6381e-03]],\n",
      "\n",
      "         [[ 1.0300e-03,  5.0179e-02, -4.3565e-02,  7.2572e-03,  5.4124e-04],\n",
      "          [ 4.8820e-02, -7.0653e-02, -9.0281e-02, -9.3963e-02,  4.8682e-02],\n",
      "          [ 9.2024e-02,  1.1466e-01,  4.1304e-02, -2.3476e-02,  2.1537e-02],\n",
      "          [-1.1409e-01,  1.3415e-02, -3.8058e-02, -8.6186e-03,  6.6672e-02],\n",
      "          [-3.9680e-02, -8.7426e-02,  7.0188e-03, -3.2031e-02, -5.3588e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.8473e-02,  5.0196e-02,  2.0160e-01,  9.7984e-02,  2.5009e-02],\n",
      "          [ 1.9605e-01,  1.4638e-01,  1.8007e-01,  1.8443e-01,  2.0294e-01],\n",
      "          [ 1.0415e-01,  1.3990e-01,  6.0541e-02,  2.1526e-01,  1.3725e-01],\n",
      "          [ 1.1589e-01,  1.6257e-01,  2.4218e-01,  1.6251e-01,  1.6299e-01],\n",
      "          [ 2.2432e-01,  1.2916e-01,  1.2925e-01,  1.4558e-01,  6.1556e-03]],\n",
      "\n",
      "         [[-4.3148e-02, -8.3872e-02, -1.0463e-01, -1.0313e-01, -1.0679e-02],\n",
      "          [-4.4514e-02, -1.7781e-01,  1.8439e-02, -3.6602e-02, -5.5025e-02],\n",
      "          [-2.1365e-02, -5.6574e-02, -1.4126e-01, -2.1229e-02, -1.9024e-01],\n",
      "          [-1.4102e-01, -7.3285e-02, -1.6985e-01,  1.2509e-02,  1.4991e-02],\n",
      "          [-3.3179e-02, -1.4919e-02, -1.9353e-01,  7.1042e-03, -7.5098e-02]],\n",
      "\n",
      "         [[-1.4850e-01, -1.5650e-01, -6.2293e-02, -3.1254e-02, -1.3700e-01],\n",
      "          [-9.6176e-02, -8.7817e-02, -1.8758e-01, -1.3813e-02, -1.1378e-01],\n",
      "          [-1.6675e-01, -1.4626e-01, -3.2701e-02, -1.9738e-01, -1.3707e-02],\n",
      "          [-1.6095e-01, -7.0138e-02, -3.8303e-02, -1.3984e-01, -1.6842e-01],\n",
      "          [-9.8659e-02, -6.0224e-02, -9.8516e-02, -3.6652e-02, -3.1845e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5868e-02,  1.1156e-01, -7.6428e-02, -1.1454e-01,  2.0634e-04],\n",
      "          [ 3.2535e-02,  1.2758e-01,  1.2133e-01,  4.3590e-02,  4.8725e-02],\n",
      "          [ 6.6313e-02,  4.7934e-03, -1.0131e-01, -4.9207e-02, -1.1222e-01],\n",
      "          [ 9.4242e-02, -5.1883e-02, -8.6807e-02, -1.9119e-02,  6.4271e-02],\n",
      "          [ 5.8985e-02,  5.0556e-02, -6.0076e-03, -1.1460e-01, -8.4892e-02]],\n",
      "\n",
      "         [[-1.0210e-01, -3.3356e-02,  6.8442e-02, -1.0533e-01, -6.6530e-02],\n",
      "          [ 1.2210e-01,  9.3549e-02,  4.8391e-02,  6.2525e-02, -5.0338e-02],\n",
      "          [-5.0929e-02,  6.9581e-02,  3.5210e-02, -4.3730e-02,  6.8127e-02],\n",
      "          [-7.3258e-02,  5.3672e-03,  9.4400e-02,  2.8378e-02, -1.1191e-01],\n",
      "          [ 2.2790e-02, -1.2288e-02,  4.3978e-02,  4.9709e-02, -1.0626e-01]],\n",
      "\n",
      "         [[-1.4800e-03,  1.3957e-01, -5.3870e-02, -1.4735e-02, -3.6558e-02],\n",
      "          [ 2.2872e-02,  4.1648e-02,  1.1687e-01,  1.0451e-01, -2.7750e-02],\n",
      "          [ 6.8420e-02, -5.2341e-02,  4.7658e-03,  2.5515e-02,  1.6970e-02],\n",
      "          [ 7.5878e-02,  5.9692e-02,  1.1513e-02,  1.1892e-01, -1.6453e-02],\n",
      "          [ 1.4242e-01,  1.1877e-01,  3.8476e-02, -1.4359e-02,  8.9257e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2509e-03, -6.2850e-02,  6.2449e-02,  8.8063e-03,  1.1066e-01],\n",
      "          [-1.1357e-01,  2.8129e-02, -1.0557e-01, -5.1484e-02, -1.1428e-02],\n",
      "          [ 9.3807e-02, -4.8045e-02, -6.7114e-02, -7.5985e-03, -1.4176e-02],\n",
      "          [-9.1584e-02,  3.1793e-03,  6.1209e-02, -4.9748e-02, -9.1772e-02],\n",
      "          [-8.1790e-02,  5.4728e-02, -7.1925e-03,  8.3563e-02, -1.0623e-02]],\n",
      "\n",
      "         [[ 2.2407e-03,  9.5927e-02,  3.7693e-02, -8.1818e-02,  2.1211e-02],\n",
      "          [-3.3027e-03, -7.5978e-02,  9.9323e-02,  5.2697e-02, -4.8777e-02],\n",
      "          [-1.0300e-01,  4.8841e-02, -9.9435e-02,  2.3274e-02, -7.2229e-02],\n",
      "          [ 1.9267e-02,  2.2934e-02,  5.6305e-02, -3.4559e-02, -1.5818e-03],\n",
      "          [-6.1964e-02,  9.2878e-03,  6.8133e-03,  1.0045e-01,  1.1116e-01]],\n",
      "\n",
      "         [[-2.0545e-02, -4.8986e-02, -1.5022e-02, -7.6355e-02, -5.3015e-02],\n",
      "          [-7.5279e-02, -7.4780e-02,  9.0214e-02,  3.1220e-02, -4.7829e-02],\n",
      "          [-1.1381e-01,  5.0366e-02, -7.1502e-02, -1.1429e-01, -1.1277e-01],\n",
      "          [ 3.6967e-02,  2.3879e-02,  1.3410e-03, -1.1083e-01,  3.7554e-02],\n",
      "          [-9.8396e-02,  1.5629e-02,  1.3082e-02, -7.9784e-02, -3.2695e-03]]],\n",
      "\n",
      "\n",
      "        [[[-8.9665e-02,  9.2446e-02, -5.5544e-02,  4.0383e-02, -1.0420e-01],\n",
      "          [ 2.4109e-02, -1.2419e-01, -2.5740e-02,  1.4531e-02, -1.2879e-02],\n",
      "          [ 4.4249e-02,  7.0219e-02, -9.3717e-02,  6.7805e-02, -8.6757e-02],\n",
      "          [-8.8680e-02, -4.0521e-02,  8.7181e-02,  6.2588e-02, -2.4862e-02],\n",
      "          [-6.9430e-02, -6.0137e-02, -6.6538e-02,  4.2187e-02, -1.7755e-02]],\n",
      "\n",
      "         [[ 8.1395e-02,  9.8363e-03,  1.0527e-01,  1.6607e-01,  1.7367e-01],\n",
      "          [ 1.0350e-01,  1.9681e-01,  6.4469e-02,  1.8143e-01,  1.6519e-01],\n",
      "          [ 1.8380e-01,  1.4370e-01, -8.4148e-03,  1.4814e-01,  1.8127e-02],\n",
      "          [ 1.5250e-02,  7.8225e-03,  3.6438e-02, -1.5574e-02,  1.9019e-01],\n",
      "          [ 5.3622e-02,  1.6768e-01,  1.9022e-01,  1.5953e-01,  1.7719e-01]],\n",
      "\n",
      "         [[-4.5931e-02, -1.6706e-01,  1.1519e-02, -1.5817e-01, -2.3946e-02],\n",
      "          [-1.0723e-01,  1.2497e-02,  1.7487e-02, -6.8855e-02, -9.4047e-02],\n",
      "          [ 2.4828e-02, -1.0119e-01, -1.4636e-01, -1.3712e-01, -1.6228e-01],\n",
      "          [ 3.4236e-02,  2.9726e-02, -8.9387e-02, -1.1427e-02,  8.5002e-03],\n",
      "          [-8.8311e-02, -3.2206e-02, -7.8615e-02, -1.1632e-01, -1.2801e-01]]]],\n",
      "       requires_grad=True))]\n",
      "\n",
      "Module Buffer List:\n",
      "[('weight_mask', tensor([[[[1., 1., 0., 0., 0.],\n",
      "          [1., 0., 1., 1., 1.],\n",
      "          [0., 1., 1., 1., 1.],\n",
      "          [0., 1., 1., 0., 1.],\n",
      "          [0., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 1., 0.],\n",
      "          [1., 1., 1., 1., 0.],\n",
      "          [1., 1., 1., 0., 1.],\n",
      "          [0., 1., 1., 0., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 0., 0.],\n",
      "          [1., 1., 0., 0., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 0., 1., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 0., 1., 1.],\n",
      "          [1., 0., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 0.],\n",
      "          [1., 1., 0., 1., 1.],\n",
      "          [1., 1., 1., 0., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1.],\n",
      "          [1., 1., 0., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 0., 1., 0., 0.],\n",
      "          [1., 0., 1., 0., 0.]],\n",
      "\n",
      "         [[0., 1., 1., 0., 0.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 0., 0.],\n",
      "          [1., 0., 1., 0., 1.],\n",
      "          [1., 1., 0., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 0.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 0.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 0.],\n",
      "          [1., 1., 0., 0., 1.],\n",
      "          [0., 1., 1., 0., 1.],\n",
      "          [1., 1., 1., 0., 0.],\n",
      "          [0., 0., 1., 0., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 0., 1.],\n",
      "          [1., 1., 1., 0., 1.],\n",
      "          [1., 1., 0., 1., 0.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 0.],\n",
      "          [0., 1., 1., 1., 1.],\n",
      "          [1., 0., 1., 1., 1.],\n",
      "          [1., 1., 1., 0., 1.],\n",
      "          [1., 1., 0., 1., 1.]],\n",
      "\n",
      "         [[1., 0., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 0., 1., 1.],\n",
      "          [1., 0., 1., 0., 1.],\n",
      "          [0., 0., 1., 1., 1.]],\n",
      "\n",
      "         [[0., 1., 1., 0., 0.],\n",
      "          [0., 1., 1., 1., 0.],\n",
      "          [1., 1., 0., 0., 0.],\n",
      "          [1., 1., 0., 1., 0.],\n",
      "          [1., 1., 1., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1., 1., 0., 1.],\n",
      "          [1., 0., 1., 1., 0.],\n",
      "          [1., 1., 1., 0., 0.],\n",
      "          [1., 0., 1., 1., 1.],\n",
      "          [1., 1., 0., 1., 0.]],\n",
      "\n",
      "         [[0., 1., 1., 1., 0.],\n",
      "          [0., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 0., 1.],\n",
      "          [0., 0., 1., 0., 0.],\n",
      "          [1., 0., 0., 1., 1.]],\n",
      "\n",
      "         [[0., 1., 0., 1., 1.],\n",
      "          [1., 1., 1., 0., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [0., 0., 0., 1., 0.],\n",
      "          [1., 0., 0., 1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 1.],\n",
      "          [0., 1., 0., 0., 0.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 0.],\n",
      "          [1., 1., 1., 1., 0.]],\n",
      "\n",
      "         [[1., 0., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 0., 1., 0.],\n",
      "          [0., 0., 0., 0., 1.],\n",
      "          [1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 0., 1., 0.],\n",
      "          [1., 0., 0., 1., 1.],\n",
      "          [0., 1., 1., 1., 1.],\n",
      "          [0., 0., 1., 0., 0.],\n",
      "          [1., 0., 1., 1., 1.]]]]))]\n"
     ]
    }
   ],
   "source": [
    "# inspect module before pruning\n",
    "print(\"\\033[1mModule Before Pruning \\033[0m\")\n",
    "module = single_pruned_model.conv1\n",
    "inspect_module(module)\n",
    "\n",
    "# prune the module (conv1 in this example)\n",
    "single_prune(single_pruned_model, module)\n",
    "\n",
    "# inspect module after pruning\n",
    "print(\"\\n\\033[1mModule After Pruning \\033[0m\")\n",
    "inspect_module(module)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-embassy",
   "metadata": {},
   "source": [
    "The pruning techniques implemented in ``torch.nn.utils.prune`` <b>compute the pruned version of the weight (by combining the mask with the original parameter)</b> and <b>store them in the attribute weight</b>. Note, this is no longer a parameter of the module, it is now simply an attribute. \n",
    "\n",
    "Notice the pruned weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "piano-criminal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0784, -0.0618, -0.0000,  0.0000,  0.0000],\n",
       "          [-0.1010,  0.0000,  0.0641,  0.0674,  0.0588],\n",
       "          [ 0.0000, -0.1063,  0.0782, -0.0892, -0.0660],\n",
       "          [ 0.0000,  0.0376,  0.0683, -0.0000, -0.0581],\n",
       "          [-0.0000,  0.0391, -0.0639, -0.0991,  0.0561]],\n",
       "\n",
       "         [[-0.0536, -0.0423,  0.1171, -0.0559, -0.0732],\n",
       "          [ 0.1101, -0.0000,  0.0000,  0.1348, -0.0000],\n",
       "          [ 0.1287,  0.1128,  0.1085,  0.0530, -0.0000],\n",
       "          [ 0.0926, -0.0594, -0.0488, -0.0000,  0.0685],\n",
       "          [ 0.0000,  0.0921,  0.0941,  0.0000,  0.0858]],\n",
       "\n",
       "         [[-0.1072, -0.1347, -0.1195,  0.0385,  0.0819],\n",
       "          [-0.0549,  0.0410, -0.1070, -0.0000, -0.0000],\n",
       "          [-0.0564, -0.0792,  0.0000, -0.0000, -0.0478],\n",
       "          [ 0.0567, -0.1115,  0.0512,  0.0782, -0.0959],\n",
       "          [-0.1335, -0.0000, -0.1121,  0.0000, -0.1167]]],\n",
       "\n",
       "\n",
       "        [[[-0.0917,  0.0000, -0.0000, -0.1037,  0.0437],\n",
       "          [ 0.0394,  0.0000,  0.0740, -0.0477,  0.1042],\n",
       "          [-0.0893,  0.1028,  0.0845, -0.1040, -0.0000],\n",
       "          [-0.0635,  0.1123, -0.0000,  0.0668,  0.0987],\n",
       "          [-0.0904,  0.0688, -0.1018, -0.0000, -0.0478]],\n",
       "\n",
       "         [[-0.1080, -0.1087, -0.1113, -0.0893, -0.0645],\n",
       "          [-0.0379,  0.0647, -0.0000, -0.1142, -0.0838],\n",
       "          [ 0.0831, -0.1125, -0.0567, -0.1044,  0.0623],\n",
       "          [ 0.0790,  0.0000, -0.0580, -0.0000,  0.0000],\n",
       "          [ 0.0484,  0.0000, -0.0538,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0502, -0.0436,  0.0000,  0.0000],\n",
       "          [ 0.0488, -0.0707, -0.0903, -0.0940,  0.0487],\n",
       "          [ 0.0920,  0.1147,  0.0413, -0.0000,  0.0000],\n",
       "          [-0.1141,  0.0000, -0.0381, -0.0000,  0.0667],\n",
       "          [-0.0397, -0.0874,  0.0000, -0.0000, -0.0536]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0785,  0.0502,  0.2016,  0.0980,  0.0000],\n",
       "          [ 0.1961,  0.1464,  0.1801,  0.1844,  0.2029],\n",
       "          [ 0.1042,  0.1399,  0.0605,  0.2153,  0.1372],\n",
       "          [ 0.1159,  0.1626,  0.2422,  0.1625,  0.1630],\n",
       "          [ 0.2243,  0.1292,  0.1293,  0.1456,  0.0000]],\n",
       "\n",
       "         [[-0.0431, -0.0839, -0.1046, -0.1031, -0.0000],\n",
       "          [-0.0445, -0.1778,  0.0000, -0.0000, -0.0550],\n",
       "          [-0.0000, -0.0566, -0.1413, -0.0000, -0.1902],\n",
       "          [-0.1410, -0.0733, -0.1698,  0.0000,  0.0000],\n",
       "          [-0.0000, -0.0000, -0.1935,  0.0000, -0.0751]],\n",
       "\n",
       "         [[-0.1485, -0.1565, -0.0623, -0.0000, -0.1370],\n",
       "          [-0.0962, -0.0878, -0.1876, -0.0000, -0.1138],\n",
       "          [-0.1668, -0.1463, -0.0000, -0.1974, -0.0000],\n",
       "          [-0.1609, -0.0701, -0.0383, -0.1398, -0.1684],\n",
       "          [-0.0987, -0.0602, -0.0985, -0.0000, -0.0000]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0459,  0.1116, -0.0764, -0.1145,  0.0000],\n",
       "          [ 0.0000,  0.1276,  0.1213,  0.0436,  0.0487],\n",
       "          [ 0.0663,  0.0000, -0.1013, -0.0492, -0.1122],\n",
       "          [ 0.0942, -0.0519, -0.0868, -0.0000,  0.0643],\n",
       "          [ 0.0590,  0.0506, -0.0000, -0.1146, -0.0849]],\n",
       "\n",
       "         [[-0.1021, -0.0000,  0.0684, -0.1053, -0.0665],\n",
       "          [ 0.1221,  0.0935,  0.0484,  0.0625, -0.0503],\n",
       "          [-0.0509,  0.0696,  0.0000, -0.0437,  0.0681],\n",
       "          [-0.0733,  0.0000,  0.0944,  0.0000, -0.1119],\n",
       "          [ 0.0000, -0.0000,  0.0440,  0.0497, -0.1063]],\n",
       "\n",
       "         [[-0.0000,  0.1396, -0.0539, -0.0000, -0.0000],\n",
       "          [ 0.0000,  0.0416,  0.1169,  0.1045, -0.0000],\n",
       "          [ 0.0684, -0.0523,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0759,  0.0597,  0.0000,  0.1189, -0.0000],\n",
       "          [ 0.1424,  0.1188,  0.0385, -0.0000,  0.0893]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000, -0.0629,  0.0624,  0.0000,  0.1107],\n",
       "          [-0.1136,  0.0000, -0.1056, -0.0515, -0.0000],\n",
       "          [ 0.0938, -0.0480, -0.0671, -0.0000, -0.0000],\n",
       "          [-0.0916,  0.0000,  0.0612, -0.0497, -0.0918],\n",
       "          [-0.0818,  0.0547, -0.0000,  0.0836, -0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0959,  0.0377, -0.0818,  0.0000],\n",
       "          [-0.0000, -0.0760,  0.0993,  0.0527, -0.0488],\n",
       "          [-0.1030,  0.0488, -0.0994,  0.0000, -0.0722],\n",
       "          [ 0.0000,  0.0000,  0.0563, -0.0000, -0.0000],\n",
       "          [-0.0620,  0.0000,  0.0000,  0.1005,  0.1112]],\n",
       "\n",
       "         [[-0.0000, -0.0490, -0.0000, -0.0764, -0.0530],\n",
       "          [-0.0753, -0.0748,  0.0902,  0.0000, -0.0478],\n",
       "          [-0.1138,  0.0504, -0.0715, -0.1143, -0.1128],\n",
       "          [ 0.0000,  0.0000,  0.0000, -0.1108,  0.0000],\n",
       "          [-0.0984,  0.0000,  0.0000, -0.0798, -0.0000]]],\n",
       "\n",
       "\n",
       "        [[[-0.0897,  0.0924, -0.0555,  0.0404, -0.1042],\n",
       "          [ 0.0000, -0.1242, -0.0000,  0.0000, -0.0000],\n",
       "          [ 0.0442,  0.0702, -0.0937,  0.0678, -0.0868],\n",
       "          [-0.0887, -0.0405,  0.0872,  0.0626, -0.0000],\n",
       "          [-0.0694, -0.0601, -0.0665,  0.0422, -0.0000]],\n",
       "\n",
       "         [[ 0.0814,  0.0000,  0.1053,  0.1661,  0.1737],\n",
       "          [ 0.1035,  0.1968,  0.0645,  0.1814,  0.1652],\n",
       "          [ 0.1838,  0.1437, -0.0000,  0.1481,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000, -0.0000,  0.1902],\n",
       "          [ 0.0536,  0.1677,  0.1902,  0.1595,  0.1772]],\n",
       "\n",
       "         [[-0.0459, -0.1671,  0.0000, -0.1582, -0.0000],\n",
       "          [-0.1072,  0.0000,  0.0000, -0.0689, -0.0940],\n",
       "          [ 0.0000, -0.1012, -0.1464, -0.1371, -0.1623],\n",
       "          [ 0.0000,  0.0000, -0.0894, -0.0000,  0.0000],\n",
       "          [-0.0883, -0.0000, -0.0786, -0.1163, -0.1280]]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-chemical",
   "metadata": {},
   "source": [
    "Lastly, Pruning is applied prior to each forward pass using PyTorch's\n",
    "``forward_pre_hooks``.\n",
    "\n",
    "Specifically, when the ``module`` is pruned, as we \n",
    "have done here, it will acquire a <b>``forward_pre_hook`` for each parameter \n",
    "associated with it that gets pruned</b>. That means pruning for each parameter \n",
    "associated with the pruned weights will be executed as well before every forward pass.\n",
    "\n",
    "In this case, since we have so far only pruned the original parameter named ``weight``, only one hook will be\n",
    "present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "modern-stephen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.nn.utils.prune.L1Unstructured object at 0x000001CF63913340>\n"
     ]
    }
   ],
   "source": [
    "for hook in module._forward_pre_hooks.values():\n",
    "    print(hook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-celebrity",
   "metadata": {},
   "source": [
    "### Serializing a Pruned Model\n",
    "\n",
    "All relevant tensors, including the ``weight_mask`` in the buffers and the original parameters\n",
    "used to compute the pruned tensors are stored in the model's ``state_dict`` \n",
    "and can therefore be easily serialized and saved, if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "marked-history",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['conv1.bias', 'conv1.weight_orig', 'conv1.weight_mask', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(single_pruned_model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-meditation",
   "metadata": {},
   "source": [
    "### Remove Pruning Re-parametrization \n",
    "\n",
    "To make the pruning permanent (i.e.: zero out the parameters), we need to remove the re-parametrization in terms\n",
    "of ``weight_orig`` and ``weight_mask``, and remove the ``forward_pre_hook``, we can use the ``remove`` functionality from ``torch.nn.utils.prune``. \n",
    "\n",
    "What we are doing here is reassigning the attribute ``weight`` to the model parameters, in its pruned version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "spread-savage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mModule Before Re-parametrization \u001b[0m\n",
      "\n",
      "Module Parameters:\n",
      "[('bias', Parameter containing:\n",
      "tensor([-0.0594, -0.0101, -0.5172, -0.0776, -0.1052, -0.1574],\n",
      "       requires_grad=True)), ('weight_orig', Parameter containing:\n",
      "tensor([[[[ 7.8413e-02, -6.1813e-02, -8.1539e-03,  1.9616e-02,  3.5149e-02],\n",
      "          [-1.0102e-01,  1.1059e-02,  6.4063e-02,  6.7392e-02,  5.8826e-02],\n",
      "          [ 2.3068e-02, -1.0635e-01,  7.8187e-02, -8.9222e-02, -6.6019e-02],\n",
      "          [ 4.4278e-03,  3.7632e-02,  6.8275e-02, -1.5092e-02, -5.8075e-02],\n",
      "          [-7.7381e-03,  3.9115e-02, -6.3891e-02, -9.9119e-02,  5.6131e-02]],\n",
      "\n",
      "         [[-5.3576e-02, -4.2260e-02,  1.1709e-01, -5.5879e-02, -7.3201e-02],\n",
      "          [ 1.1009e-01, -3.2467e-02,  2.8705e-02,  1.3480e-01, -2.5989e-02],\n",
      "          [ 1.2869e-01,  1.1275e-01,  1.0845e-01,  5.3049e-02, -3.2747e-02],\n",
      "          [ 9.2628e-02, -5.9429e-02, -4.8797e-02, -3.7474e-02,  6.8518e-02],\n",
      "          [ 3.5430e-02,  9.2111e-02,  9.4129e-02,  2.4983e-02,  8.5755e-02]],\n",
      "\n",
      "         [[-1.0724e-01, -1.3468e-01, -1.1950e-01,  3.8523e-02,  8.1936e-02],\n",
      "          [-5.4905e-02,  4.0974e-02, -1.0695e-01, -2.7370e-02, -2.5292e-02],\n",
      "          [-5.6430e-02, -7.9165e-02,  2.9678e-02, -3.5022e-02, -4.7790e-02],\n",
      "          [ 5.6684e-02, -1.1153e-01,  5.1191e-02,  7.8209e-02, -9.5925e-02],\n",
      "          [-1.3347e-01, -8.4023e-03, -1.1207e-01,  2.4432e-02, -1.1667e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.1700e-02,  2.9676e-02, -3.1128e-02, -1.0366e-01,  4.3732e-02],\n",
      "          [ 3.9392e-02,  1.4168e-02,  7.4021e-02, -4.7708e-02,  1.0424e-01],\n",
      "          [-8.9294e-02,  1.0285e-01,  8.4486e-02, -1.0398e-01, -1.1351e-02],\n",
      "          [-6.3500e-02,  1.1228e-01, -6.1671e-03,  6.6752e-02,  9.8750e-02],\n",
      "          [-9.0442e-02,  6.8810e-02, -1.0180e-01, -3.2472e-02, -4.7764e-02]],\n",
      "\n",
      "         [[-1.0797e-01, -1.0875e-01, -1.1131e-01, -8.9271e-02, -6.4491e-02],\n",
      "          [-3.7913e-02,  6.4726e-02, -1.8501e-02, -1.1425e-01, -8.3750e-02],\n",
      "          [ 8.3092e-02, -1.1248e-01, -5.6682e-02, -1.0438e-01,  6.2318e-02],\n",
      "          [ 7.9042e-02,  1.0216e-02, -5.7988e-02, -2.7897e-02,  6.9322e-03],\n",
      "          [ 4.8448e-02,  2.0391e-03, -5.3808e-02,  5.6547e-03,  3.6381e-03]],\n",
      "\n",
      "         [[ 1.0300e-03,  5.0179e-02, -4.3565e-02,  7.2572e-03,  5.4124e-04],\n",
      "          [ 4.8820e-02, -7.0653e-02, -9.0281e-02, -9.3963e-02,  4.8682e-02],\n",
      "          [ 9.2024e-02,  1.1466e-01,  4.1304e-02, -2.3476e-02,  2.1537e-02],\n",
      "          [-1.1409e-01,  1.3415e-02, -3.8058e-02, -8.6186e-03,  6.6672e-02],\n",
      "          [-3.9680e-02, -8.7426e-02,  7.0188e-03, -3.2031e-02, -5.3588e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.8473e-02,  5.0196e-02,  2.0160e-01,  9.7984e-02,  2.5009e-02],\n",
      "          [ 1.9605e-01,  1.4638e-01,  1.8007e-01,  1.8443e-01,  2.0294e-01],\n",
      "          [ 1.0415e-01,  1.3990e-01,  6.0541e-02,  2.1526e-01,  1.3725e-01],\n",
      "          [ 1.1589e-01,  1.6257e-01,  2.4218e-01,  1.6251e-01,  1.6299e-01],\n",
      "          [ 2.2432e-01,  1.2916e-01,  1.2925e-01,  1.4558e-01,  6.1556e-03]],\n",
      "\n",
      "         [[-4.3148e-02, -8.3872e-02, -1.0463e-01, -1.0313e-01, -1.0679e-02],\n",
      "          [-4.4514e-02, -1.7781e-01,  1.8439e-02, -3.6602e-02, -5.5025e-02],\n",
      "          [-2.1365e-02, -5.6574e-02, -1.4126e-01, -2.1229e-02, -1.9024e-01],\n",
      "          [-1.4102e-01, -7.3285e-02, -1.6985e-01,  1.2509e-02,  1.4991e-02],\n",
      "          [-3.3179e-02, -1.4919e-02, -1.9353e-01,  7.1042e-03, -7.5098e-02]],\n",
      "\n",
      "         [[-1.4850e-01, -1.5650e-01, -6.2293e-02, -3.1254e-02, -1.3700e-01],\n",
      "          [-9.6176e-02, -8.7817e-02, -1.8758e-01, -1.3813e-02, -1.1378e-01],\n",
      "          [-1.6675e-01, -1.4626e-01, -3.2701e-02, -1.9738e-01, -1.3707e-02],\n",
      "          [-1.6095e-01, -7.0138e-02, -3.8303e-02, -1.3984e-01, -1.6842e-01],\n",
      "          [-9.8659e-02, -6.0224e-02, -9.8516e-02, -3.6652e-02, -3.1845e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5868e-02,  1.1156e-01, -7.6428e-02, -1.1454e-01,  2.0634e-04],\n",
      "          [ 3.2535e-02,  1.2758e-01,  1.2133e-01,  4.3590e-02,  4.8725e-02],\n",
      "          [ 6.6313e-02,  4.7934e-03, -1.0131e-01, -4.9207e-02, -1.1222e-01],\n",
      "          [ 9.4242e-02, -5.1883e-02, -8.6807e-02, -1.9119e-02,  6.4271e-02],\n",
      "          [ 5.8985e-02,  5.0556e-02, -6.0076e-03, -1.1460e-01, -8.4892e-02]],\n",
      "\n",
      "         [[-1.0210e-01, -3.3356e-02,  6.8442e-02, -1.0533e-01, -6.6530e-02],\n",
      "          [ 1.2210e-01,  9.3549e-02,  4.8391e-02,  6.2525e-02, -5.0338e-02],\n",
      "          [-5.0929e-02,  6.9581e-02,  3.5210e-02, -4.3730e-02,  6.8127e-02],\n",
      "          [-7.3258e-02,  5.3672e-03,  9.4400e-02,  2.8378e-02, -1.1191e-01],\n",
      "          [ 2.2790e-02, -1.2288e-02,  4.3978e-02,  4.9709e-02, -1.0626e-01]],\n",
      "\n",
      "         [[-1.4800e-03,  1.3957e-01, -5.3870e-02, -1.4735e-02, -3.6558e-02],\n",
      "          [ 2.2872e-02,  4.1648e-02,  1.1687e-01,  1.0451e-01, -2.7750e-02],\n",
      "          [ 6.8420e-02, -5.2341e-02,  4.7658e-03,  2.5515e-02,  1.6970e-02],\n",
      "          [ 7.5878e-02,  5.9692e-02,  1.1513e-02,  1.1892e-01, -1.6453e-02],\n",
      "          [ 1.4242e-01,  1.1877e-01,  3.8476e-02, -1.4359e-02,  8.9257e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2509e-03, -6.2850e-02,  6.2449e-02,  8.8063e-03,  1.1066e-01],\n",
      "          [-1.1357e-01,  2.8129e-02, -1.0557e-01, -5.1484e-02, -1.1428e-02],\n",
      "          [ 9.3807e-02, -4.8045e-02, -6.7114e-02, -7.5985e-03, -1.4176e-02],\n",
      "          [-9.1584e-02,  3.1793e-03,  6.1209e-02, -4.9748e-02, -9.1772e-02],\n",
      "          [-8.1790e-02,  5.4728e-02, -7.1925e-03,  8.3563e-02, -1.0623e-02]],\n",
      "\n",
      "         [[ 2.2407e-03,  9.5927e-02,  3.7693e-02, -8.1818e-02,  2.1211e-02],\n",
      "          [-3.3027e-03, -7.5978e-02,  9.9323e-02,  5.2697e-02, -4.8777e-02],\n",
      "          [-1.0300e-01,  4.8841e-02, -9.9435e-02,  2.3274e-02, -7.2229e-02],\n",
      "          [ 1.9267e-02,  2.2934e-02,  5.6305e-02, -3.4559e-02, -1.5818e-03],\n",
      "          [-6.1964e-02,  9.2878e-03,  6.8133e-03,  1.0045e-01,  1.1116e-01]],\n",
      "\n",
      "         [[-2.0545e-02, -4.8986e-02, -1.5022e-02, -7.6355e-02, -5.3015e-02],\n",
      "          [-7.5279e-02, -7.4780e-02,  9.0214e-02,  3.1220e-02, -4.7829e-02],\n",
      "          [-1.1381e-01,  5.0366e-02, -7.1502e-02, -1.1429e-01, -1.1277e-01],\n",
      "          [ 3.6967e-02,  2.3879e-02,  1.3410e-03, -1.1083e-01,  3.7554e-02],\n",
      "          [-9.8396e-02,  1.5629e-02,  1.3082e-02, -7.9784e-02, -3.2695e-03]]],\n",
      "\n",
      "\n",
      "        [[[-8.9665e-02,  9.2446e-02, -5.5544e-02,  4.0383e-02, -1.0420e-01],\n",
      "          [ 2.4109e-02, -1.2419e-01, -2.5740e-02,  1.4531e-02, -1.2879e-02],\n",
      "          [ 4.4249e-02,  7.0219e-02, -9.3717e-02,  6.7805e-02, -8.6757e-02],\n",
      "          [-8.8680e-02, -4.0521e-02,  8.7181e-02,  6.2588e-02, -2.4862e-02],\n",
      "          [-6.9430e-02, -6.0137e-02, -6.6538e-02,  4.2187e-02, -1.7755e-02]],\n",
      "\n",
      "         [[ 8.1395e-02,  9.8363e-03,  1.0527e-01,  1.6607e-01,  1.7367e-01],\n",
      "          [ 1.0350e-01,  1.9681e-01,  6.4469e-02,  1.8143e-01,  1.6519e-01],\n",
      "          [ 1.8380e-01,  1.4370e-01, -8.4148e-03,  1.4814e-01,  1.8127e-02],\n",
      "          [ 1.5250e-02,  7.8225e-03,  3.6438e-02, -1.5574e-02,  1.9019e-01],\n",
      "          [ 5.3622e-02,  1.6768e-01,  1.9022e-01,  1.5953e-01,  1.7719e-01]],\n",
      "\n",
      "         [[-4.5931e-02, -1.6706e-01,  1.1519e-02, -1.5817e-01, -2.3946e-02],\n",
      "          [-1.0723e-01,  1.2497e-02,  1.7487e-02, -6.8855e-02, -9.4047e-02],\n",
      "          [ 2.4828e-02, -1.0119e-01, -1.4636e-01, -1.3712e-01, -1.6228e-01],\n",
      "          [ 3.4236e-02,  2.9726e-02, -8.9387e-02, -1.1427e-02,  8.5002e-03],\n",
      "          [-8.8311e-02, -3.2206e-02, -7.8615e-02, -1.1632e-01, -1.2801e-01]]]],\n",
      "       requires_grad=True))]\n",
      "\n",
      "Module Buffer List:\n",
      "[('weight_mask', tensor([[[[1., 1., 0., 0., 0.],\n",
      "          [1., 0., 1., 1., 1.],\n",
      "          [0., 1., 1., 1., 1.],\n",
      "          [0., 1., 1., 0., 1.],\n",
      "          [0., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1.],\n",
      "          [1., 0., 0., 1., 0.],\n",
      "          [1., 1., 1., 1., 0.],\n",
      "          [1., 1., 1., 0., 1.],\n",
      "          [0., 1., 1., 0., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 0., 0.],\n",
      "          [1., 1., 0., 0., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 0., 1., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 0., 1., 1.],\n",
      "          [1., 0., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 0.],\n",
      "          [1., 1., 0., 1., 1.],\n",
      "          [1., 1., 1., 0., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 1.],\n",
      "          [1., 1., 0., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 0., 1., 0., 0.],\n",
      "          [1., 0., 1., 0., 0.]],\n",
      "\n",
      "         [[0., 1., 1., 0., 0.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 0., 0.],\n",
      "          [1., 0., 1., 0., 1.],\n",
      "          [1., 1., 0., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 0.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 0.]],\n",
      "\n",
      "         [[1., 1., 1., 1., 0.],\n",
      "          [1., 1., 0., 0., 1.],\n",
      "          [0., 1., 1., 0., 1.],\n",
      "          [1., 1., 1., 0., 0.],\n",
      "          [0., 0., 1., 0., 1.]],\n",
      "\n",
      "         [[1., 1., 1., 0., 1.],\n",
      "          [1., 1., 1., 0., 1.],\n",
      "          [1., 1., 0., 1., 0.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 0.],\n",
      "          [0., 1., 1., 1., 1.],\n",
      "          [1., 0., 1., 1., 1.],\n",
      "          [1., 1., 1., 0., 1.],\n",
      "          [1., 1., 0., 1., 1.]],\n",
      "\n",
      "         [[1., 0., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 0., 1., 1.],\n",
      "          [1., 0., 1., 0., 1.],\n",
      "          [0., 0., 1., 1., 1.]],\n",
      "\n",
      "         [[0., 1., 1., 0., 0.],\n",
      "          [0., 1., 1., 1., 0.],\n",
      "          [1., 1., 0., 0., 0.],\n",
      "          [1., 1., 0., 1., 0.],\n",
      "          [1., 1., 1., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 1., 1., 0., 1.],\n",
      "          [1., 0., 1., 1., 0.],\n",
      "          [1., 1., 1., 0., 0.],\n",
      "          [1., 0., 1., 1., 1.],\n",
      "          [1., 1., 0., 1., 0.]],\n",
      "\n",
      "         [[0., 1., 1., 1., 0.],\n",
      "          [0., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 0., 1.],\n",
      "          [0., 0., 1., 0., 0.],\n",
      "          [1., 0., 0., 1., 1.]],\n",
      "\n",
      "         [[0., 1., 0., 1., 1.],\n",
      "          [1., 1., 1., 0., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [0., 0., 0., 1., 0.],\n",
      "          [1., 0., 0., 1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 1.],\n",
      "          [0., 1., 0., 0., 0.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 0.],\n",
      "          [1., 1., 1., 1., 0.]],\n",
      "\n",
      "         [[1., 0., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1.],\n",
      "          [1., 1., 0., 1., 0.],\n",
      "          [0., 0., 0., 0., 1.],\n",
      "          [1., 1., 1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 0., 1., 0.],\n",
      "          [1., 0., 0., 1., 1.],\n",
      "          [0., 1., 1., 1., 1.],\n",
      "          [0., 0., 1., 0., 0.],\n",
      "          [1., 0., 1., 1., 1.]]]]))]\n",
      "\n",
      "\u001b[1mModule After Re-parametrization \u001b[0m\n",
      "\n",
      "Module Parameters:\n",
      "[('bias', Parameter containing:\n",
      "tensor([-0.0594, -0.0101, -0.5172, -0.0776, -0.1052, -0.1574],\n",
      "       requires_grad=True)), ('weight', Parameter containing:\n",
      "tensor([[[[ 0.0784, -0.0618, -0.0000,  0.0000,  0.0000],\n",
      "          [-0.1010,  0.0000,  0.0641,  0.0674,  0.0588],\n",
      "          [ 0.0000, -0.1063,  0.0782, -0.0892, -0.0660],\n",
      "          [ 0.0000,  0.0376,  0.0683, -0.0000, -0.0581],\n",
      "          [-0.0000,  0.0391, -0.0639, -0.0991,  0.0561]],\n",
      "\n",
      "         [[-0.0536, -0.0423,  0.1171, -0.0559, -0.0732],\n",
      "          [ 0.1101, -0.0000,  0.0000,  0.1348, -0.0000],\n",
      "          [ 0.1287,  0.1128,  0.1085,  0.0530, -0.0000],\n",
      "          [ 0.0926, -0.0594, -0.0488, -0.0000,  0.0685],\n",
      "          [ 0.0000,  0.0921,  0.0941,  0.0000,  0.0858]],\n",
      "\n",
      "         [[-0.1072, -0.1347, -0.1195,  0.0385,  0.0819],\n",
      "          [-0.0549,  0.0410, -0.1070, -0.0000, -0.0000],\n",
      "          [-0.0564, -0.0792,  0.0000, -0.0000, -0.0478],\n",
      "          [ 0.0567, -0.1115,  0.0512,  0.0782, -0.0959],\n",
      "          [-0.1335, -0.0000, -0.1121,  0.0000, -0.1167]]],\n",
      "\n",
      "\n",
      "        [[[-0.0917,  0.0000, -0.0000, -0.1037,  0.0437],\n",
      "          [ 0.0394,  0.0000,  0.0740, -0.0477,  0.1042],\n",
      "          [-0.0893,  0.1028,  0.0845, -0.1040, -0.0000],\n",
      "          [-0.0635,  0.1123, -0.0000,  0.0668,  0.0987],\n",
      "          [-0.0904,  0.0688, -0.1018, -0.0000, -0.0478]],\n",
      "\n",
      "         [[-0.1080, -0.1087, -0.1113, -0.0893, -0.0645],\n",
      "          [-0.0379,  0.0647, -0.0000, -0.1142, -0.0838],\n",
      "          [ 0.0831, -0.1125, -0.0567, -0.1044,  0.0623],\n",
      "          [ 0.0790,  0.0000, -0.0580, -0.0000,  0.0000],\n",
      "          [ 0.0484,  0.0000, -0.0538,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0502, -0.0436,  0.0000,  0.0000],\n",
      "          [ 0.0488, -0.0707, -0.0903, -0.0940,  0.0487],\n",
      "          [ 0.0920,  0.1147,  0.0413, -0.0000,  0.0000],\n",
      "          [-0.1141,  0.0000, -0.0381, -0.0000,  0.0667],\n",
      "          [-0.0397, -0.0874,  0.0000, -0.0000, -0.0536]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0785,  0.0502,  0.2016,  0.0980,  0.0000],\n",
      "          [ 0.1961,  0.1464,  0.1801,  0.1844,  0.2029],\n",
      "          [ 0.1042,  0.1399,  0.0605,  0.2153,  0.1372],\n",
      "          [ 0.1159,  0.1626,  0.2422,  0.1625,  0.1630],\n",
      "          [ 0.2243,  0.1292,  0.1293,  0.1456,  0.0000]],\n",
      "\n",
      "         [[-0.0431, -0.0839, -0.1046, -0.1031, -0.0000],\n",
      "          [-0.0445, -0.1778,  0.0000, -0.0000, -0.0550],\n",
      "          [-0.0000, -0.0566, -0.1413, -0.0000, -0.1902],\n",
      "          [-0.1410, -0.0733, -0.1698,  0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000, -0.1935,  0.0000, -0.0751]],\n",
      "\n",
      "         [[-0.1485, -0.1565, -0.0623, -0.0000, -0.1370],\n",
      "          [-0.0962, -0.0878, -0.1876, -0.0000, -0.1138],\n",
      "          [-0.1668, -0.1463, -0.0000, -0.1974, -0.0000],\n",
      "          [-0.1609, -0.0701, -0.0383, -0.1398, -0.1684],\n",
      "          [-0.0987, -0.0602, -0.0985, -0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0459,  0.1116, -0.0764, -0.1145,  0.0000],\n",
      "          [ 0.0000,  0.1276,  0.1213,  0.0436,  0.0487],\n",
      "          [ 0.0663,  0.0000, -0.1013, -0.0492, -0.1122],\n",
      "          [ 0.0942, -0.0519, -0.0868, -0.0000,  0.0643],\n",
      "          [ 0.0590,  0.0506, -0.0000, -0.1146, -0.0849]],\n",
      "\n",
      "         [[-0.1021, -0.0000,  0.0684, -0.1053, -0.0665],\n",
      "          [ 0.1221,  0.0935,  0.0484,  0.0625, -0.0503],\n",
      "          [-0.0509,  0.0696,  0.0000, -0.0437,  0.0681],\n",
      "          [-0.0733,  0.0000,  0.0944,  0.0000, -0.1119],\n",
      "          [ 0.0000, -0.0000,  0.0440,  0.0497, -0.1063]],\n",
      "\n",
      "         [[-0.0000,  0.1396, -0.0539, -0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0416,  0.1169,  0.1045, -0.0000],\n",
      "          [ 0.0684, -0.0523,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0759,  0.0597,  0.0000,  0.1189, -0.0000],\n",
      "          [ 0.1424,  0.1188,  0.0385, -0.0000,  0.0893]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000, -0.0629,  0.0624,  0.0000,  0.1107],\n",
      "          [-0.1136,  0.0000, -0.1056, -0.0515, -0.0000],\n",
      "          [ 0.0938, -0.0480, -0.0671, -0.0000, -0.0000],\n",
      "          [-0.0916,  0.0000,  0.0612, -0.0497, -0.0918],\n",
      "          [-0.0818,  0.0547, -0.0000,  0.0836, -0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0959,  0.0377, -0.0818,  0.0000],\n",
      "          [-0.0000, -0.0760,  0.0993,  0.0527, -0.0488],\n",
      "          [-0.1030,  0.0488, -0.0994,  0.0000, -0.0722],\n",
      "          [ 0.0000,  0.0000,  0.0563, -0.0000, -0.0000],\n",
      "          [-0.0620,  0.0000,  0.0000,  0.1005,  0.1112]],\n",
      "\n",
      "         [[-0.0000, -0.0490, -0.0000, -0.0764, -0.0530],\n",
      "          [-0.0753, -0.0748,  0.0902,  0.0000, -0.0478],\n",
      "          [-0.1138,  0.0504, -0.0715, -0.1143, -0.1128],\n",
      "          [ 0.0000,  0.0000,  0.0000, -0.1108,  0.0000],\n",
      "          [-0.0984,  0.0000,  0.0000, -0.0798, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0897,  0.0924, -0.0555,  0.0404, -0.1042],\n",
      "          [ 0.0000, -0.1242, -0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0442,  0.0702, -0.0937,  0.0678, -0.0868],\n",
      "          [-0.0887, -0.0405,  0.0872,  0.0626, -0.0000],\n",
      "          [-0.0694, -0.0601, -0.0665,  0.0422, -0.0000]],\n",
      "\n",
      "         [[ 0.0814,  0.0000,  0.1053,  0.1661,  0.1737],\n",
      "          [ 0.1035,  0.1968,  0.0645,  0.1814,  0.1652],\n",
      "          [ 0.1838,  0.1437, -0.0000,  0.1481,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000, -0.0000,  0.1902],\n",
      "          [ 0.0536,  0.1677,  0.1902,  0.1595,  0.1772]],\n",
      "\n",
      "         [[-0.0459, -0.1671,  0.0000, -0.1582, -0.0000],\n",
      "          [-0.1072,  0.0000,  0.0000, -0.0689, -0.0940],\n",
      "          [ 0.0000, -0.1012, -0.1464, -0.1371, -0.1623],\n",
      "          [ 0.0000,  0.0000, -0.0894, -0.0000,  0.0000],\n",
      "          [-0.0883, -0.0000, -0.0786, -0.1163, -0.1280]]]], requires_grad=True))]\n",
      "\n",
      "Module Buffer List:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# inspect module before re-parametrization\n",
    "print(\"\\n\\033[1mModule Before Re-parametrization \\033[0m\")\n",
    "inspect_module(module)\n",
    "\n",
    "# re-parametrization\n",
    "prune.remove(module, 'weight')\n",
    "\n",
    "# inspect module after re-parametrization\n",
    "print(\"\\n\\033[1mModule After Re-parametrization \\033[0m\")\n",
    "inspect_module(module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-kitty",
   "metadata": {},
   "source": [
    "### Compare Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "laden-tribe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing size of models\n",
      "model:  original_model  \t Size (KB): 8935.103\n",
      "model:  single_pruned_model  \t Size (KB): 8935.103\n",
      "1.00 times smaller\n",
      "\n",
      "Comparing latency of models\n",
      "model:  original_model  \t prediction time: 0.003998756408691406s\n",
      "model:  single_pruned_model  \t prediction time: 0.0030012130737304688s\n",
      "\n",
      "Comparing accuracy of models\n",
      "model:  original_model  \t Test Accuracy: 0.74\n",
      "model:  single_pruned_model  \t Test Accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "INFERENCE_IMAGE_PATH = \"../../resources/data/fruits_image_classification/test/apple/image1.jpg\"\n",
    "TEST_DATASET_ROOTDIR = \"../../resources/data/fruits_image_classification/test\"\n",
    "\n",
    "# load image\n",
    "inference_image = load_image(INFERENCE_IMAGE_PATH)\n",
    "\n",
    "# load test dataset\n",
    "test_dataloader = load_dataset(TEST_DATASET_ROOTDIR)\n",
    "\n",
    "compare_performance(original_model, single_pruned_model, \"original_model\", \"single_pruned_model\", inference_image, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-nothing",
   "metadata": {},
   "source": [
    "## Global Pruning\n",
    "\n",
    "So far, we only looked at what is usually referred to as \"local\" pruning, i.e. the practice of **pruning tensors in a model one by one**, by comparing the statistics (weight magnitude, activation, gradient, etc.) of each entry exclusively to the other entries in that tensor.\n",
    "\n",
    "\n",
    "However, a common and perhaps more powerful technique is to **prune the model all at once, by removing (for example) the lowest 20% of connections across the whole model**, instead of removing the lowest 20% of connections in each layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-governor",
   "metadata": {},
   "source": [
    "### Global Pruning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "southeast-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_pruned_model = copy.deepcopy(model)\n",
    "\n",
    "parameters_to_prune = (\n",
    "    (global_pruned_model.conv1, 'weight'),\n",
    "    (global_pruned_model.conv2, 'weight'),\n",
    "    (global_pruned_model.fc1, 'weight'),\n",
    "    (global_pruned_model.fc2, 'weight'),\n",
    "    (global_pruned_model.fc3, 'weight'),\n",
    ")\n",
    "\n",
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured, \n",
    "    amount=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-alert",
   "metadata": {},
   "source": [
    "### Re-parametrization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "norman-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-parametrization\n",
    "for module, parameter_name in parameters_to_prune:\n",
    "    prune.remove(module, parameter_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-vaccine",
   "metadata": {},
   "source": [
    "### Compare Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cardiac-least",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing size of models\n",
      "model:  original_model  \t Size (KB): 8935.103\n",
      "model:  global_pruned_model  \t Size (KB): 8935.103\n",
      "1.00 times smaller\n",
      "\n",
      "Comparing latency of models\n",
      "model:  original_model  \t prediction time: 0.003000497817993164s\n",
      "model:  global_pruned_model  \t prediction time: 0.0020029544830322266s\n",
      "\n",
      "Comparing accuracy of models\n",
      "model:  original_model  \t Test Accuracy: 0.74\n",
      "model:  global_pruned_model  \t Test Accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "compare_performance(original_model, global_pruned_model, \"original_model\", \"global_pruned_model\", inference_image, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-niger",
   "metadata": {},
   "source": [
    "## Why is the pruned model performing the same as the unpruned model?\n",
    "\n",
    "Since Pytorch is representing the pruned model (Sparse model) in the same architecture as the unpruned model (dense model), hence the number of parameters are still the same, only the values of the parameters have been zero-ed out. \n",
    "\n",
    "However, Pytorch community is actively working on the support of converting the sparse neural networks to use sparse tensors. Once it is supported, we would be able to see the performance difference in running a sparse neural network after pruning comparing to its original dense neural network before pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "viral-awareness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 7.8413e-02, -6.1813e-02, -8.1539e-03,  1.9616e-02,  3.5149e-02],\n",
       "          [-1.0102e-01,  1.1059e-02,  6.4063e-02,  6.7392e-02,  5.8826e-02],\n",
       "          [ 2.3068e-02, -1.0635e-01,  7.8187e-02, -8.9222e-02, -6.6019e-02],\n",
       "          [ 4.4278e-03,  3.7632e-02,  6.8275e-02, -1.5092e-02, -5.8075e-02],\n",
       "          [-7.7381e-03,  3.9115e-02, -6.3891e-02, -9.9119e-02,  5.6131e-02]],\n",
       "\n",
       "         [[-5.3576e-02, -4.2260e-02,  1.1709e-01, -5.5879e-02, -7.3201e-02],\n",
       "          [ 1.1009e-01, -3.2467e-02,  2.8705e-02,  1.3480e-01, -2.5989e-02],\n",
       "          [ 1.2869e-01,  1.1275e-01,  1.0845e-01,  5.3049e-02, -3.2747e-02],\n",
       "          [ 9.2628e-02, -5.9429e-02, -4.8797e-02, -3.7474e-02,  6.8518e-02],\n",
       "          [ 3.5430e-02,  9.2111e-02,  9.4129e-02,  2.4983e-02,  8.5755e-02]],\n",
       "\n",
       "         [[-1.0724e-01, -1.3468e-01, -1.1950e-01,  3.8523e-02,  8.1936e-02],\n",
       "          [-5.4905e-02,  4.0974e-02, -1.0695e-01, -2.7370e-02, -2.5292e-02],\n",
       "          [-5.6430e-02, -7.9165e-02,  2.9678e-02, -3.5022e-02, -4.7790e-02],\n",
       "          [ 5.6684e-02, -1.1153e-01,  5.1191e-02,  7.8209e-02, -9.5925e-02],\n",
       "          [-1.3347e-01, -8.4023e-03, -1.1207e-01,  2.4432e-02, -1.1667e-01]]],\n",
       "\n",
       "\n",
       "        [[[-9.1700e-02,  2.9676e-02, -3.1128e-02, -1.0366e-01,  4.3732e-02],\n",
       "          [ 3.9392e-02,  1.4168e-02,  7.4021e-02, -4.7708e-02,  1.0424e-01],\n",
       "          [-8.9294e-02,  1.0285e-01,  8.4486e-02, -1.0398e-01, -1.1351e-02],\n",
       "          [-6.3500e-02,  1.1228e-01, -6.1671e-03,  6.6752e-02,  9.8750e-02],\n",
       "          [-9.0442e-02,  6.8810e-02, -1.0180e-01, -3.2472e-02, -4.7764e-02]],\n",
       "\n",
       "         [[-1.0797e-01, -1.0875e-01, -1.1131e-01, -8.9271e-02, -6.4491e-02],\n",
       "          [-3.7913e-02,  6.4726e-02, -1.8501e-02, -1.1425e-01, -8.3750e-02],\n",
       "          [ 8.3092e-02, -1.1248e-01, -5.6682e-02, -1.0438e-01,  6.2318e-02],\n",
       "          [ 7.9042e-02,  1.0216e-02, -5.7988e-02, -2.7897e-02,  6.9322e-03],\n",
       "          [ 4.8448e-02,  2.0391e-03, -5.3808e-02,  5.6547e-03,  3.6381e-03]],\n",
       "\n",
       "         [[ 1.0300e-03,  5.0179e-02, -4.3565e-02,  7.2572e-03,  5.4124e-04],\n",
       "          [ 4.8820e-02, -7.0653e-02, -9.0281e-02, -9.3963e-02,  4.8682e-02],\n",
       "          [ 9.2024e-02,  1.1466e-01,  4.1304e-02, -2.3476e-02,  2.1537e-02],\n",
       "          [-1.1409e-01,  1.3415e-02, -3.8058e-02, -8.6186e-03,  6.6672e-02],\n",
       "          [-3.9680e-02, -8.7426e-02,  7.0188e-03, -3.2031e-02, -5.3588e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 7.8473e-02,  5.0196e-02,  2.0160e-01,  9.7984e-02,  2.5009e-02],\n",
       "          [ 1.9605e-01,  1.4638e-01,  1.8007e-01,  1.8443e-01,  2.0294e-01],\n",
       "          [ 1.0415e-01,  1.3990e-01,  6.0541e-02,  2.1526e-01,  1.3725e-01],\n",
       "          [ 1.1589e-01,  1.6257e-01,  2.4218e-01,  1.6251e-01,  1.6299e-01],\n",
       "          [ 2.2432e-01,  1.2916e-01,  1.2925e-01,  1.4558e-01,  6.1556e-03]],\n",
       "\n",
       "         [[-4.3148e-02, -8.3872e-02, -1.0463e-01, -1.0313e-01, -1.0679e-02],\n",
       "          [-4.4514e-02, -1.7781e-01,  1.8439e-02, -3.6602e-02, -5.5025e-02],\n",
       "          [-2.1365e-02, -5.6574e-02, -1.4126e-01, -2.1229e-02, -1.9024e-01],\n",
       "          [-1.4102e-01, -7.3285e-02, -1.6985e-01,  1.2509e-02,  1.4991e-02],\n",
       "          [-3.3179e-02, -1.4919e-02, -1.9353e-01,  7.1042e-03, -7.5098e-02]],\n",
       "\n",
       "         [[-1.4850e-01, -1.5650e-01, -6.2293e-02, -3.1254e-02, -1.3700e-01],\n",
       "          [-9.6176e-02, -8.7817e-02, -1.8758e-01, -1.3813e-02, -1.1378e-01],\n",
       "          [-1.6675e-01, -1.4626e-01, -3.2701e-02, -1.9738e-01, -1.3707e-02],\n",
       "          [-1.6095e-01, -7.0138e-02, -3.8303e-02, -1.3984e-01, -1.6842e-01],\n",
       "          [-9.8659e-02, -6.0224e-02, -9.8516e-02, -3.6652e-02, -3.1845e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 4.5868e-02,  1.1156e-01, -7.6428e-02, -1.1454e-01,  2.0634e-04],\n",
       "          [ 3.2535e-02,  1.2758e-01,  1.2133e-01,  4.3590e-02,  4.8725e-02],\n",
       "          [ 6.6313e-02,  4.7934e-03, -1.0131e-01, -4.9207e-02, -1.1222e-01],\n",
       "          [ 9.4242e-02, -5.1883e-02, -8.6807e-02, -1.9119e-02,  6.4271e-02],\n",
       "          [ 5.8985e-02,  5.0556e-02, -6.0076e-03, -1.1460e-01, -8.4892e-02]],\n",
       "\n",
       "         [[-1.0210e-01, -3.3356e-02,  6.8442e-02, -1.0533e-01, -6.6530e-02],\n",
       "          [ 1.2210e-01,  9.3549e-02,  4.8391e-02,  6.2525e-02, -5.0338e-02],\n",
       "          [-5.0929e-02,  6.9581e-02,  3.5210e-02, -4.3730e-02,  6.8127e-02],\n",
       "          [-7.3258e-02,  5.3672e-03,  9.4400e-02,  2.8378e-02, -1.1191e-01],\n",
       "          [ 2.2790e-02, -1.2288e-02,  4.3978e-02,  4.9709e-02, -1.0626e-01]],\n",
       "\n",
       "         [[-1.4800e-03,  1.3957e-01, -5.3870e-02, -1.4735e-02, -3.6558e-02],\n",
       "          [ 2.2872e-02,  4.1648e-02,  1.1687e-01,  1.0451e-01, -2.7750e-02],\n",
       "          [ 6.8420e-02, -5.2341e-02,  4.7658e-03,  2.5515e-02,  1.6970e-02],\n",
       "          [ 7.5878e-02,  5.9692e-02,  1.1513e-02,  1.1892e-01, -1.6453e-02],\n",
       "          [ 1.4242e-01,  1.1877e-01,  3.8476e-02, -1.4359e-02,  8.9257e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.2509e-03, -6.2850e-02,  6.2449e-02,  8.8063e-03,  1.1066e-01],\n",
       "          [-1.1357e-01,  2.8129e-02, -1.0557e-01, -5.1484e-02, -1.1428e-02],\n",
       "          [ 9.3807e-02, -4.8045e-02, -6.7114e-02, -7.5985e-03, -1.4176e-02],\n",
       "          [-9.1584e-02,  3.1793e-03,  6.1209e-02, -4.9748e-02, -9.1772e-02],\n",
       "          [-8.1790e-02,  5.4728e-02, -7.1925e-03,  8.3563e-02, -1.0623e-02]],\n",
       "\n",
       "         [[ 2.2407e-03,  9.5927e-02,  3.7693e-02, -8.1818e-02,  2.1211e-02],\n",
       "          [-3.3027e-03, -7.5978e-02,  9.9323e-02,  5.2697e-02, -4.8777e-02],\n",
       "          [-1.0300e-01,  4.8841e-02, -9.9435e-02,  2.3274e-02, -7.2229e-02],\n",
       "          [ 1.9267e-02,  2.2934e-02,  5.6305e-02, -3.4559e-02, -1.5818e-03],\n",
       "          [-6.1964e-02,  9.2878e-03,  6.8133e-03,  1.0045e-01,  1.1116e-01]],\n",
       "\n",
       "         [[-2.0545e-02, -4.8986e-02, -1.5022e-02, -7.6355e-02, -5.3015e-02],\n",
       "          [-7.5279e-02, -7.4780e-02,  9.0214e-02,  3.1220e-02, -4.7829e-02],\n",
       "          [-1.1381e-01,  5.0366e-02, -7.1502e-02, -1.1429e-01, -1.1277e-01],\n",
       "          [ 3.6967e-02,  2.3879e-02,  1.3410e-03, -1.1083e-01,  3.7554e-02],\n",
       "          [-9.8396e-02,  1.5629e-02,  1.3082e-02, -7.9784e-02, -3.2695e-03]]],\n",
       "\n",
       "\n",
       "        [[[-8.9665e-02,  9.2446e-02, -5.5544e-02,  4.0383e-02, -1.0420e-01],\n",
       "          [ 2.4109e-02, -1.2419e-01, -2.5740e-02,  1.4531e-02, -1.2879e-02],\n",
       "          [ 4.4249e-02,  7.0219e-02, -9.3717e-02,  6.7805e-02, -8.6757e-02],\n",
       "          [-8.8680e-02, -4.0521e-02,  8.7181e-02,  6.2588e-02, -2.4862e-02],\n",
       "          [-6.9430e-02, -6.0137e-02, -6.6538e-02,  4.2187e-02, -1.7755e-02]],\n",
       "\n",
       "         [[ 8.1395e-02,  9.8363e-03,  1.0527e-01,  1.6607e-01,  1.7367e-01],\n",
       "          [ 1.0350e-01,  1.9681e-01,  6.4469e-02,  1.8143e-01,  1.6519e-01],\n",
       "          [ 1.8380e-01,  1.4370e-01, -8.4148e-03,  1.4814e-01,  1.8127e-02],\n",
       "          [ 1.5250e-02,  7.8225e-03,  3.6438e-02, -1.5574e-02,  1.9019e-01],\n",
       "          [ 5.3622e-02,  1.6768e-01,  1.9022e-01,  1.5953e-01,  1.7719e-01]],\n",
       "\n",
       "         [[-4.5931e-02, -1.6706e-01,  1.1519e-02, -1.5817e-01, -2.3946e-02],\n",
       "          [-1.0723e-01,  1.2497e-02,  1.7487e-02, -6.8855e-02, -9.4047e-02],\n",
       "          [ 2.4828e-02, -1.0119e-01, -1.4636e-01, -1.3712e-01, -1.6228e-01],\n",
       "          [ 3.4236e-02,  2.9726e-02, -8.9387e-02, -1.1427e-02,  8.5002e-03],\n",
       "          [-8.8311e-02, -3.2206e-02, -7.8615e-02, -1.1632e-01, -1.2801e-01]]]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check to see if pruning has been done successfully\n",
    "original_model.conv1.weight  # unpruned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "logical-ecology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.0784, -0.0618, -0.0082,  0.0196,  0.0351],\n",
       "          [-0.1010,  0.0111,  0.0641,  0.0674,  0.0588],\n",
       "          [ 0.0231, -0.1063,  0.0782, -0.0892, -0.0660],\n",
       "          [ 0.0044,  0.0376,  0.0683, -0.0151, -0.0581],\n",
       "          [-0.0077,  0.0391, -0.0639, -0.0991,  0.0561]],\n",
       "\n",
       "         [[-0.0536, -0.0423,  0.1171, -0.0559, -0.0732],\n",
       "          [ 0.1101, -0.0325,  0.0287,  0.1348, -0.0260],\n",
       "          [ 0.1287,  0.1128,  0.1085,  0.0530, -0.0327],\n",
       "          [ 0.0926, -0.0594, -0.0488, -0.0375,  0.0685],\n",
       "          [ 0.0354,  0.0921,  0.0941,  0.0250,  0.0858]],\n",
       "\n",
       "         [[-0.1072, -0.1347, -0.1195,  0.0385,  0.0819],\n",
       "          [-0.0549,  0.0410, -0.1070, -0.0274, -0.0253],\n",
       "          [-0.0564, -0.0792,  0.0297, -0.0350, -0.0478],\n",
       "          [ 0.0567, -0.1115,  0.0512,  0.0782, -0.0959],\n",
       "          [-0.1335, -0.0084, -0.1121,  0.0244, -0.1167]]],\n",
       "\n",
       "\n",
       "        [[[-0.0917,  0.0297, -0.0311, -0.1037,  0.0437],\n",
       "          [ 0.0394,  0.0142,  0.0740, -0.0477,  0.1042],\n",
       "          [-0.0893,  0.1028,  0.0845, -0.1040, -0.0114],\n",
       "          [-0.0635,  0.1123, -0.0062,  0.0668,  0.0987],\n",
       "          [-0.0904,  0.0688, -0.1018, -0.0325, -0.0478]],\n",
       "\n",
       "         [[-0.1080, -0.1087, -0.1113, -0.0893, -0.0645],\n",
       "          [-0.0379,  0.0647, -0.0185, -0.1142, -0.0838],\n",
       "          [ 0.0831, -0.1125, -0.0567, -0.1044,  0.0623],\n",
       "          [ 0.0790,  0.0102, -0.0580, -0.0279,  0.0069],\n",
       "          [ 0.0484,  0.0000, -0.0538,  0.0057,  0.0036]],\n",
       "\n",
       "         [[ 0.0000,  0.0502, -0.0436,  0.0073,  0.0000],\n",
       "          [ 0.0488, -0.0707, -0.0903, -0.0940,  0.0487],\n",
       "          [ 0.0920,  0.1147,  0.0413, -0.0235,  0.0215],\n",
       "          [-0.1141,  0.0134, -0.0381, -0.0086,  0.0667],\n",
       "          [-0.0397, -0.0874,  0.0070, -0.0320, -0.0536]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0785,  0.0502,  0.2016,  0.0980,  0.0250],\n",
       "          [ 0.1961,  0.1464,  0.1801,  0.1844,  0.2029],\n",
       "          [ 0.1042,  0.1399,  0.0605,  0.2153,  0.1372],\n",
       "          [ 0.1159,  0.1626,  0.2422,  0.1625,  0.1630],\n",
       "          [ 0.2243,  0.1292,  0.1293,  0.1456,  0.0062]],\n",
       "\n",
       "         [[-0.0431, -0.0839, -0.1046, -0.1031, -0.0107],\n",
       "          [-0.0445, -0.1778,  0.0184, -0.0366, -0.0550],\n",
       "          [-0.0214, -0.0566, -0.1413, -0.0212, -0.1902],\n",
       "          [-0.1410, -0.0733, -0.1698,  0.0125,  0.0150],\n",
       "          [-0.0332, -0.0149, -0.1935,  0.0071, -0.0751]],\n",
       "\n",
       "         [[-0.1485, -0.1565, -0.0623, -0.0313, -0.1370],\n",
       "          [-0.0962, -0.0878, -0.1876, -0.0138, -0.1138],\n",
       "          [-0.1668, -0.1463, -0.0327, -0.1974, -0.0137],\n",
       "          [-0.1609, -0.0701, -0.0383, -0.1398, -0.1684],\n",
       "          [-0.0987, -0.0602, -0.0985, -0.0367, -0.0318]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0459,  0.1116, -0.0764, -0.1145,  0.0000],\n",
       "          [ 0.0325,  0.1276,  0.1213,  0.0436,  0.0487],\n",
       "          [ 0.0663,  0.0048, -0.1013, -0.0492, -0.1122],\n",
       "          [ 0.0942, -0.0519, -0.0868, -0.0191,  0.0643],\n",
       "          [ 0.0590,  0.0506, -0.0060, -0.1146, -0.0849]],\n",
       "\n",
       "         [[-0.1021, -0.0334,  0.0684, -0.1053, -0.0665],\n",
       "          [ 0.1221,  0.0935,  0.0484,  0.0625, -0.0503],\n",
       "          [-0.0509,  0.0696,  0.0352, -0.0437,  0.0681],\n",
       "          [-0.0733,  0.0054,  0.0944,  0.0284, -0.1119],\n",
       "          [ 0.0228, -0.0123,  0.0440,  0.0497, -0.1063]],\n",
       "\n",
       "         [[-0.0000,  0.1396, -0.0539, -0.0147, -0.0366],\n",
       "          [ 0.0229,  0.0416,  0.1169,  0.1045, -0.0278],\n",
       "          [ 0.0684, -0.0523,  0.0048,  0.0255,  0.0170],\n",
       "          [ 0.0759,  0.0597,  0.0115,  0.1189, -0.0165],\n",
       "          [ 0.1424,  0.1188,  0.0385, -0.0144,  0.0893]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000, -0.0629,  0.0624,  0.0088,  0.1107],\n",
       "          [-0.1136,  0.0281, -0.1056, -0.0515, -0.0114],\n",
       "          [ 0.0938, -0.0480, -0.0671, -0.0076, -0.0142],\n",
       "          [-0.0916,  0.0032,  0.0612, -0.0497, -0.0918],\n",
       "          [-0.0818,  0.0547, -0.0072,  0.0836, -0.0106]],\n",
       "\n",
       "         [[ 0.0022,  0.0959,  0.0377, -0.0818,  0.0212],\n",
       "          [-0.0033, -0.0760,  0.0993,  0.0527, -0.0488],\n",
       "          [-0.1030,  0.0488, -0.0994,  0.0233, -0.0722],\n",
       "          [ 0.0193,  0.0229,  0.0563, -0.0346, -0.0000],\n",
       "          [-0.0620,  0.0093,  0.0068,  0.1005,  0.1112]],\n",
       "\n",
       "         [[-0.0205, -0.0490, -0.0150, -0.0764, -0.0530],\n",
       "          [-0.0753, -0.0748,  0.0902,  0.0312, -0.0478],\n",
       "          [-0.1138,  0.0504, -0.0715, -0.1143, -0.1128],\n",
       "          [ 0.0370,  0.0239,  0.0000, -0.1108,  0.0376],\n",
       "          [-0.0984,  0.0156,  0.0131, -0.0798, -0.0033]]],\n",
       "\n",
       "\n",
       "        [[[-0.0897,  0.0924, -0.0555,  0.0404, -0.1042],\n",
       "          [ 0.0241, -0.1242, -0.0257,  0.0145, -0.0129],\n",
       "          [ 0.0442,  0.0702, -0.0937,  0.0678, -0.0868],\n",
       "          [-0.0887, -0.0405,  0.0872,  0.0626, -0.0249],\n",
       "          [-0.0694, -0.0601, -0.0665,  0.0422, -0.0178]],\n",
       "\n",
       "         [[ 0.0814,  0.0098,  0.1053,  0.1661,  0.1737],\n",
       "          [ 0.1035,  0.1968,  0.0645,  0.1814,  0.1652],\n",
       "          [ 0.1838,  0.1437, -0.0084,  0.1481,  0.0181],\n",
       "          [ 0.0153,  0.0078,  0.0364, -0.0156,  0.1902],\n",
       "          [ 0.0536,  0.1677,  0.1902,  0.1595,  0.1772]],\n",
       "\n",
       "         [[-0.0459, -0.1671,  0.0115, -0.1582, -0.0239],\n",
       "          [-0.1072,  0.0125,  0.0175, -0.0689, -0.0940],\n",
       "          [ 0.0248, -0.1012, -0.1464, -0.1371, -0.1623],\n",
       "          [ 0.0342,  0.0297, -0.0894, -0.0114,  0.0085],\n",
       "          [-0.0883, -0.0322, -0.0786, -0.1163, -0.1280]]]], requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check to see if pruning has been done successfully\n",
    "global_pruned_model.conv1.weight  # pruned model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-bachelor",
   "metadata": {},
   "source": [
    "## Compare Sparsity\n",
    "\n",
    "GlobalSparsity = (Sum of elements in weight matrix of the module where element == 0 in all modules) / (Number of elements in the weight matrix in all modules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "western-marker",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_global_sparsity(model):\n",
    "    return 100. * float(\n",
    "        torch.sum(model.conv1.weight == 0)\n",
    "        + torch.sum(model.conv2.weight == 0)\n",
    "        + torch.sum(model.fc1.weight == 0)\n",
    "        + torch.sum(model.fc2.weight == 0)\n",
    "        + torch.sum(model.fc3.weight == 0)\n",
    "    ) / float(\n",
    "        model.conv1.weight.nelement()\n",
    "        + model.conv2.weight.nelement()\n",
    "        + model.fc1.weight.nelement()\n",
    "        + model.fc2.weight.nelement()\n",
    "        + model.fc3.weight.nelement()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eight-contrast",
   "metadata": {},
   "source": [
    "Remember we are measuring the sparsity of the model, not density. We can see that our globally pruned model is around 30% sparser than the unpruned model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "neural-grant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity for unpruned model: 0.00%\n",
      "Global sparsity for locally pruned model: 0.01%\n",
      "Global sparsity for globally pruned model: 30.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"Global sparsity for unpruned model: {:.2f}%\".format(calculate_global_sparsity(original_model)))\n",
    "print(\"Global sparsity for locally pruned model: {:.2f}%\".format(calculate_global_sparsity(single_pruned_model)))\n",
    "print(\"Global sparsity for globally pruned model: {:.2f}%\".format(calculate_global_sparsity(global_pruned_model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-parking",
   "metadata": {},
   "source": [
    "## Additional Notes\n",
    "\n",
    "As of June 2021, Pytorch is not supporting the conversion of the sparse neural networks to use sparse tensor yet. As mentioned previously, Pytorch is representing the pruned model (sparse model) in the same architecture as the unpruned model (dense model), hence the number of parameters are still the same, only the values of the parameters have been zero-ed out.\n",
    "\n",
    "Hence this might not decrease the model size nor increase inference speed.\n",
    "\n",
    "However, we can see the promising result of optimising the model with model pruning + model quantization as shown by [Tensorflow](https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras) and it created a \n",
    "- 3x smaller model from pruning \n",
    "- 10x smaller model from pruning + quantization\n",
    "\n",
    "while the accuracy still persists."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-trial",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Pruning for Neural Networks by Lei Mao](https://leimao.github.io/article/Neural-Networks-Pruning/)\n",
    "- [PyTorch Pruning by Lei Mao](https://leimao.github.io/blog/PyTorch-Pruning/)\n",
    "- [Pruning Tutorial by Pytorch](https://pytorch.org/tutorials/intermediate/pruning_tutorial.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deploy] *",
   "language": "python",
   "name": "conda-env-deploy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
